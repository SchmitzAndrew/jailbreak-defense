# Jailbreak Defense

Training a classifier to detect if a prompt is a jailbreak attempt to create a safeguard for LLM-based applications. 

Dataset: [Jailbreak Prompts Dataset](https://github.com/verazuo/jailbreak_llms)

Project website: https://schmitzandrew.github.io/jailbreak-defense/
